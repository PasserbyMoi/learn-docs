## 线程安全
当多个线程访问某一个类、对象或方法时，这个类、对象或方法都能表现出与单线程执行时一致的行为，那么这个类、对象或方法就是线程安全的。

- 线程安全问题都是由全局变量及静态变量引起的
- 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的
- 若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全

### 同步和异步
**同步：** 必须等待方法执行完毕，才能向下执行，共享资源访问的时候，为了保证线程安全，必须同步。 

**异步：** 不用等待其他方法执行完毕，即可立即执行，例如Aja×异步。

#### 对象锁的同步和异步
对象锁只针对 synchronized 修饰的方法生效、对象中的所有 synchronized 方法都会同步执行、而非 synchronized 方法异步执行

> **避免误区：** 类中有两个 synchronized 方法，两个线程分别调用两个方法，相互之间也需要竞争锁，因为两个方法从属于一个对象，而我们是在对象上加锁

### 脏读
由于同步和异步方法的执行个性，如果不从全局上进行并发设计很可能会引起数据的不一致，也就是所谓的脏读。
- 多个线程访问同一个资源，在一个线程修改数据的过程中，有另外的线程来读取数据，就会引起脏读的产生。
- 为了避免脏读我们一定要保证数据修改操作的原子性、并且对读取操作也要进行同步控制

### 锁

#### 重入锁
- 同一个线程得到了一个对象的锁之后，再次请求此对象时可以再次获得该对象的锁。
- 同一个对象内的多个 synchronized 方法可以锁重入
- 父子类可以锁重入

#### 死锁
两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。
此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

#### 锁失效
- 不要在线程中修改对象锁的引用，引用被改变会导致锁失效。
- 在线程中修改了锁对象的属性，而不修改引用则不会引起锁失效、不会产生线程安全问题。  
> 线程A修改了对象锁的引用，则线程B实际的到了新的对象锁，而不是锁被释放了，因此引发了线程安全问题。

#### 锁释放
一个线程在获得锁之后执行操作，发生错误抛出异常，则自动释放锁
1. 可以利用抛出异常，主动释放锁
2. 程序异常时防止资源被死锁、无法释放
3. 异常释放锁可能导致数据不一致，则自动释放锁

#### synchronized
synchronized 的作用是加锁，所有的 synchronized 方法都会顺序执行，（这里只占用CPU的顺序）。

**Synchronized 方法执行方式：**  
- 首先尝试获得锁，如果获得锁，则执行 synchronized 的方法体内容。  
- 如果无法获得锁则等待，并且不断的尝试去获得锁，一旦锁被释放，则多个线程会同时去尝试获得所，造成锁竞争问题。  
- 锁竞争问题，在高并发、线程数量高时会引起CPU占用居高不下，或者直接宕机。  

**Synchronized 锁竞争：**  
- synchronized 可以达到更细粒度的控制当前对象锁、类锁、任意对象锁，同类型锁之间互斥，不同类型的锁之间互不干扰  
- synchronized 作用在非静态方法上代表的对象锁，一个对象一个锁，多个对象之间不会发生锁竞争  
- synchronized 作用在静态方法上则升级为类锁，所有对象共享一把锁，存在锁竞争  

### 线程通信

##### 标识位/变量
使用循环监控标识位或变量

##### wait/notify
- wait 等待，释放锁
- notify 通知等待线程，不释放锁
- notifyAll 通知所有等待线程，不释放锁
- wait/notify 必须与 synchronized 一同使用

### volatile
强制线程到共享内存中读取数据，而不从线程工作内存中读取，从而使变量在多个线程间可见。
volatile 属于轻量级的同步，性能比 synchronized 强很多（不加锁），但是只保证线程见的可见性，并不能替代 synchronized 的同步功能，netty 框架中大量使用了 volatile

> static 保证唯一性，不保证一致性，多个实例共享一个静态变量。
> volatile 保证一致性，不保证唯一性，多个实例有多个 volatile 变量。

### CAS(原子操作)
使用 AtomicInteger 等原子类可以保证共享变量的原子性，但是 Atomic 类不能保证成员方法的原子性

> Atomic 类采用了 CAS 非锁机制

### ThreadLocal
使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

### 容器

#### 同步类容器
Vector、HashTable 等古老的并发容器，都是使用 Collections.synchronized 等工厂方法创建的。
这种方法会在整个对象上加锁，并发状态下只能有一个线程访问容器对象，性能很低。

**使用以下方法使容器支持多线程**
- Collections.synchronizedCollection(Collection<T> c);
- Collections.synchronizedList(List<T> list);
- Collections.synchronizedSet(Set<T> s);
- Collections.synchronizedSortedSet(SortedSet<T> s);
- Collections.synchronizedNavigableSet(NavigableSet<T> s);
- Collections.synchronizedMap(Map<K,V> m);
- Collections.synchronizedSortedMap(TreeMap<K,V> m);
- Collections.synchronizedNavigableMap(NavigableMap<K,V> m);

#### 并发类容器

> JDK5.0 之后提供了多种并发类容易可以替代同步类容器，提升性能、吞吐量

##### Map
- ConcurrentHashMap 替代 HashMap、HashTable
- ConcurrentSkipListMap 替代 TreeMap (Collections.synchronizedSortedMap(TreeMap<K,V> m))
- ConcurrentHashMap 将 hash 分为 16 个 segment，每个 segment 单独进行锁控制，从而减小了锁的粒度，提升性能。
- ConcurrentSkipListMap 线程安全的有序的哈希表，适用于高并发的场景，使用跳表实现。

##### COW(List/Set)
Copy On Write 容器，简称 COW；写时复制容器，向容器中添加元素时，先将容器 copy 出一个新容器，然后将元素添加到新容器中，再将原容器的引用指向新容器。
并发读的时候不需要锁定容器，因为原容器没有变化，使用的是一种读写分离的思想。
由于每次更新都会复制新容器，所以如果数据量较大，并且更新操作频繁则对内存消耗很高，建议在高并发读的场景下使用 

- CopyOnWriteArrayList
- CopyOnWriteArraySet 基于 CopyOnWriteArrayList 实现，其唯一的不同是在add时调用的是 CopyOnWriteArrayList 的 addIfAbsent 方法，adIfAbsent方法同样采用锁保护，并创建一个新的大小 +1 的 Object 数组。
遍历当前 Object 数组，如 Object 数组中己有了当前元素，则直接返回，如果没有则放入Object数组的尾部，并返回。从以上分析可见，copy0nWriteArraySet 在 add 时每次都要进行数组的遍历，因此其性能会低于 CopyOnWriteArrayList.


### 队列
> ConcurrentLinkedQueue 性能优于 BlockingQueue

#### 并发无阻塞式队列
ConcurrentLinkedQueue 并发无阻塞队列，实现 Queue 接口
- 无锁
- 无阻塞
- 高性能
- 线程安全
- 无界(无大小限制)
- 不允许 null 值


#### 并发阻塞式队列

> BlockingQueue(接口) 发阻塞队列，实现 Queue 接口

##### ArrayBlockingQueue:

> 内部实现维护了一个定长数组用于缓存数据，内部没有采用读写分离，写入和读取数据不能同时进行，创建时指定容量。

- 基于数组实现
- 阻塞
- 有界队列
- 不允许 null 值

**方法说明：**
- peek：读取第一个元素；队列为空时，返回 null、不阻塞、不抛异常
- poll：读取第一个元素并移除；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- take：读取第一个元素；队列为空时，永久阻塞、不抛异常
- add：添加，队列满抛出异常
- offer：添加，队列满不阻塞、不抛出异常；可设置阻塞等待时间，超时后不阻塞、不抛异常
- put：添加，队列永远阻塞
- drainTo：取出 maxElements 个元素放入集合 c，并移除；队列为空时，返回 null、不阻塞、不抛异常；  
           int drainTo(Collection<? super E> c, int maxElements = Integer.MAX_VALUE)

##### LinkedBlockingQueue:
> 内部使用链表实现，内部没有采用读写分离，写入和读取数据不能同时进行。与 ArrayBlockingQueue 不同的是，inkedBlockingQueue 创建时可以选择指定或者不指定长度。效率低于 LinkedBlockingQueue。

- 基于链表实现
- 阻塞
- 有界队列 | 无界队列
- 不允许 null 值

**方法说明：**
指定大小时，方法与 ArrayBlockingQueue 操作方法完全一致；不指定大小时，添加不存在队列满的问题。

##### PriorityBlockingQueue:
> 一个带有优先级的无界阻塞队列，默认初始化长度 11，也可以手动指定，但是队列会自动扩容
>
> 资源被耗尽时导致 OutOfMemoryError 
>
> 不允许使用 null
>
> 不允许插入不可比较的对象（导致抛出 ClassCastException），加入的对象需实现 Comparable 接口
>
> 调用 take 方法后才会对元素排序

- 基于数组实现
- 阻塞
- 无界
- 不允许 null 值
- 调用 take 方法后才会对元素排序

**方法说明：**
- peek：读取第一个元素；队列为空时，返回 null、不阻塞、不抛异常
- poll：读取第一个元素并移除；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- take：读取第一个元素；队列为空时，永久阻塞、不抛异常
- add：内部调用了 offer 方法
- put：内部调用了 offer 方法
- offer：添加 ，可指定超时时间，但参数会被忽略
- drainTo：取出 maxElements 个元素放入集合 c，并移除；队列为空时，返回 null、不阻塞、不抛异常；  
           int drainTo(Collection<? super E> c, int maxElements = Integer.MAX_VALUE)

##### SynchronousQueue:
> 没有任何容量，必须现有线程先从队列中 take，才能向 queue 中 add 数据，否则会抛出队列己满的异常。
>
> 不能使用peek方法取数据，此方法底层没有实现，会直接返回 null。

**方法说明：**
- take：读取数据；队列为空时，永久阻塞
- poll：读取数据；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- add：添加，队列没有线程 take/poll 时抛出异常；
- put：添加，队列没有线程 take/poll 时阻塞；


##### DelayQueue：
> Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。
>
> 该队列的头部是延迟期满后保存时间最长的 Delayed 元素。
>
> 如果延迟都还没有期满，则队列没有头部，并且 p 将返回 null。
>
> 当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于0的值时，将发生到期。
>
> 即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。
>
> 例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用null元素。内部元素需实现 Delayed 接口
>
> 场景：缓存到期删除、任务超时处理、空闲链接关闭等

- 基于 PriorityQueue 实现
- 阻塞
- 无界
- 不允许 null 值

## Concurrent 同步类工具
- CountDownLatch
- CyclicBarrier
- Semaphore
- Exchanger
- ReentrantLock
- ReentrantReadWriteLock

### CountDownLatch
> 允许一个或多个线程等待一系列指定操作的完成。CountDownLatch以一个给定的数量初始化。
>
> countDown() 每被调用一次，这一数量就减一。
>
> 通过调用 await() 方法之一，线程可以阻塞等待这一数量到达零。

**常用方法说明：**

- CountDownLatch(int count)
  - 初始化对象并设置计数大小

- CountDownLatch.await() 
    - 导致当前线程等到锁存器倒计数到零，除非线程是 interrupted 状态。
    - 如果当前计数为零，则此方法立即返回。
    - 如果当前线程在进入此方法时设置其中断状态或者在在等待时被中断，则抛出 InterruptedException 并清除当前线程的中断状态
    - 如果当前计数大于零，则当前线程因线程调度而被禁用，并且在发生以下两种情况之一前处于休眠状态：

        - 由于调用 countDown 方法计数达到零; 
        - 其他线程中断当前线程
- countDownLatch.countDown()   
    - 减少锁存器的计数，如果计数达到零，则释放所有等待的线程。  
    - 如果当前计数大于零，则递减。 
    - 如果新计数为零，则重新启用所有等待线程以进行线程调度。
    - 如果当前计数等于零，则没有任何反应。
- countDownLatch.await(long timeout, TimeUnit unit)
    - 可设置等待超时时间，其他同 countDownLatch.countDown() 方法

- getCount()
  - 返回当前计数，此方法通常用于调试和测试目的

### CyclicBarrier
> 允许一组线程互相等待，直到到达某个公共屏障点(common barrier point)。
>
> 在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时很有用。
>
> 因为该 barrier 在释放等待线程后可以重用，所以称它为循环的 barrier.
>
> 需要所有的子任务都完成时，才执行主任务，这个时候就可以选择使用 CyclicBarrier。

**常用方法说明：**

- CyclicBarrier(int parties, Runnable barrierAction)
  - 创建 CyclicBarrier 并设置等待线程数量，当屏障触发时指定预定义的操作 barrierAction
- CyclicBarrier(int parties)
  - 创建 CyclicBarrier 并设置等待线程数量
- getParties()
  - 返回跳过此障碍所需的参与方数量

- CyclicBarrier.await() 
  - 如果当前线程不是最后一个到达那么它就因线程调度而被禁用，并且在发生以下情况之一前处于休眠状态：
    - 当前线程被其他线程中断
    - 其他线程处于中断或等待状态
    - 其他线程等待屏障超时
    - 其他线程调用 reset 方法重置屏障
  - 如果当前线程在进入此方法时设置其中断状态或在等待时被打断，则抛出 InterruptedException 并且当前线程
      中断状态被清除    
  - 如果任何线程等待时， reset 方法被调用或者屏障状态被破坏，则抛出 BrokenBarrierException
  - 如果任何线程在等待时被中断， 所有其他等待的线程将抛出  BrokenBarrierException，屏障被破坏
- CyclicBarrier.await(long timeout, TimeUnit unit)
  - 可设置等待超时时间，其他同 CyclicBarrier.countDown() 方法
- CyclicBarrier.isBroken()   
  - 查询此屏障是否处于损坏状态。  

- CyclicBarrier.reset()
  - 将屏障重置为其初始状态。
  - 如果任何一方正在等待屏障，他们将返回 BrokenBarrierException。
  - 由于其他原因发生破损后的重置可能很复杂；线程需要以其他方式重新同步，并选择一个来执行重置。如果可能，最好为线程创建新的屏障。
- CyclicBarrier.getNumberWaiting()
  - 返回当前在屏障处等待的方数。此方法主要用于调试和断言。

### Semaphore

> semaphore —个计数信号量。信号量维护了一八许可集合；通过 acquire() 和 release() 来获取和释放访问许可证。只有通过acuire获取了许可证的线程才能执行，否则阻塞。通过 release 释放许可证其私线程才能进行获取。
>
> Semaphore有两种模式，公平模式和非公平模式。公平模式就是调用acquire的顺序就是获取许可证的顺序，遵循FIFO；而非公平模式是抢占式的，也就是有可能一个新的获取线程恰好在一个许可证释放时得到了这个许可证，而前面还有等待的线程。

### Exchanger

### ReentrantLock

### ReentrantReadWriteLock

## 线程池

newCachedThreadPool

> 具有缓存性质的线程池，线程最大空闲时间60s，线程可重复利用（缓存特性)，没有最大线程数限制。任务耗时端，数量大。

newFixedThreadPool 

> 具有固定数量的线程池，核心线程数等于最大线程数，线程最大空闲时间为0，执行完毕即销毁，超出最大线程数进行等待。高并发下控制性能。

newScheduledThreadPool 

> 具有时间调度特性的线程池，必须初始化核心线程数，底层使用 DelayedWorkQueue 实现延迟特性。

newSingleThreadExecutor 

> 核心线程数与最大线程数均为1，用于不需要并发顺序执行。

```java
public class ThreadPoolExecutor extends AbstractExecutorService {
    .....
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue,RejectedExecutionHandler handler);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
        BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);
    ...
}

public abstract class AbstractExecutorService implements ExecutorService {
 
    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) { };
    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) { };
    public Future<?> submit(Runnable task) {};
    public <T> Future<T> submit(Runnable task, T result) { };
    public <T> Future<T> submit(Callable<T> task) { };
    
    private <T> T doInvokeAny(Collection<? extends Callable<T>> tasks, boolean timed, long nanos)
        throws InterruptedException, ExecutionException, TimeoutException {
    };
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks)
        throws InterruptedException, ExecutionException {
    };
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks,
                           long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException {
    };
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException {
    };
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
        throws InterruptedException {
    };
}
```



### 参数说明

#### corePoolSize

核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了 prestartAllCoreThreads() 或者prestartCoreThread() 方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建 corePoolSize 个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到 corePoolSize 后，就会把到达的任务放到缓存队列当中；

#### maximumPoolSize

线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；

#### keepAliveTime

表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；

#### unit

参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性：

- TimeUnit.DAYS;               //天
- TimeUnit.HOURS;             //小时
- TimeUnit.MINUTES;           //分钟
- TimeUnit.SECONDS;            //秒
- TimeUnit.MILLISECONDS;      //毫秒
- TimeUnit.MICROSECONDS;      //微妙
- TimeUnit.NANOSECONDS;       //纳秒

#### workQueue

一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：

- ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务； 
- LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQuene； 
- SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene； 
- DelayedWorkQueue：支持定时
- PriorityBlockingQuene：有优先级的无界阻塞队列；

#### threadFactory

创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为`DefaultThreadFactory`，即`AbortPolicy`

#### handler

线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，有以下四种取值：

- ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。 
- ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 
- ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
- ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 

> 也可以根据应用场景实现 RejectedExecutionHandler 接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。


## 线程设计模式

### Future

> 简单来说，客户端请求之后，先返回一个应答结果，然后异步的去准备数据，客户端可以先去处理其他事情，当需要最终结果的时候再来获取，如果此时数据己经准备好，则将真实数据返回；如果此时数据还没有准备好，则阻塞等待。

```java
ExecutorService executorService = Executors.newFixedThreadPool(2);
Future<?> future = executorService.submit(new Caller("12345"));
Future<?> future1 = executorService.submit(new Caller("54321"));
Thread.sleep(2000);
System.out.println("Result: " + future.get());
System.out.println("Result: " + future1.get());
executorService.shutdown();

class Caller implements Callable<String> {
    private String string;
    public Caller(String string) {
        this.string = string;
    }    
    @Override
    public String call() throws Exception {
        Thread.sleep(5000);
        return string + "22222222";
    }   
}
```

### Master-Worker

> Master一worker模式是一种将串行任务并行化的方案，被分解的子任务在系统中可以被并行处理，同时，如果有需要，Master进程不需要等待所有子任务都完成计算，就可以根据己有的部分结果集计算最终结果集。
>
> 客户端将所有任务提交给Master，Master分配worker去并发处理任务，并将每一个任务的处理结果返回给Master，所有的任务处理完毕后，由Master进行结果汇总再返回给Client


### Producer-Consumer（生产者消费者）

# Disruptor 高并发框架

# RateLimiter 高并发访问限流



# RabbitMQ 面试要点

## 1. 如何确保消息正确地发送至RabbitMQ？

RabbitMQ使用发送方确认模式，确保消息正确地发送到RabbitMQ。 

发送方确认模式：将信道设置成confirm模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的ID。一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一ID）。如果RabbitMQ发生内部错误从而导致消息丢失，会发送一条nack（not acknowledged，未确认）消息。 

发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。 

## 2. 如何确保消息接收方消费了消息？

接收方消息确认机制：消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ才能安全地把消息从队列中删除。 

这里并没有用到超时机制，RabbitMQ仅通过Consumer的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ给了Consumer足够长的时间来处理消息。 

下面罗列几种特殊情况：

- 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要根据bizId去重）
- 如果消费者接收到消息却没有确认消息，连接也未断开，则RabbitMQ认为该消费者繁忙，将不会给该消费者分发更多的消息。

## 3. 如何避免消息重复投递或重复消费？

在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。 

## 4. 消息基于什么传输？

由于TCP连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ使用信道的方式来传输数据。信道是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。 

## 5. 消息如何分发？

若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。 

## 6. 消息怎么路由？

从概念上来说，消息路由必须有三部分：**交换器、路由、绑定**。生产者把消息发布到交换器上；绑定决定了消息如何从路由器路由到特定的队列；消息最终到达队列，并被消费者接收。 

1. 消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。
2. 通过队列路由键，可以把队列绑定到交换器上。
3. 消息到达交换器后，RabbitMQ会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）。如果能够匹配到队列，则消息会投递到相应队列中；如果不能匹配到任何队列，消息将进入 “黑洞”。

常用的交换器主要分为一下三种：

- direct：如果路由键完全匹配，消息就被投递到相应的队列
- fanout：如果交换器收到消息，将会广播到所有绑定的队列上
- topic：可以使来自不同源头的消息能够到达同一个队列。 使用topic交换器时，可以使用通配符，比如：“*” 匹配特定位置的任意文本， “.” 把路由键分为了几部分，“#” 匹配所有规则等。特别注意：发往topic交换器的消息不能随意的设置选择键（routing_key），必须是由"."隔开的一系列的标识符组成。 

## 7. 如何确保消息不丢失？

消息持久化的前提是：将交换器/队列的durable属性设置为true，表示交换器/队列是持久交换器/队列，在服务器崩溃或重启之后不需要重新创建交换器/队列（交换器/队列会自动创建）。 

如果消息想要从Rabbit崩溃中恢复，那么消息必须：

- 在消息发布前，通过把它的 “投递模式” 选项设置为2（持久）来把消息标记成持久化
- 将消息发送到持久交换器
- 消息到达持久队列

RabbitMQ确保持久性消息能从服务器重启中恢复的方式是，将它们写入磁盘上的一个持久化日志文件，当发布一条持久性消息到持久交换器上时，Rabbit会在消息提交到日志文件后才发送响应（如果消息路由到了非持久队列，它会自动从持久化日志中移除）。一旦消费者从持久队列中消费了一条持久化消息，RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集。如果持久化消息在被消费之前RabbitMQ重启，那么Rabbit会自动重建交换器和队列（以及绑定），并重播持久化日志文件中的消息到合适的队列或者交换器上。 

## 8. 使用RabbitMQ有什么好处？

- 应用解耦（系统拆分）
- 异步处理（预约挂号业务处理成功后，异步发送短信、推送消息、日志记录等）
- 消息分发
- 流量削峰
- 消息缓冲
- ......

##  9. 其他

RabbitMQ是 **消息投递服务**，在应用程序和服务器之间扮演路由器的角色，而应用程序或服务器可以发送和接收包裹。其通信方式是一种 “**发后即忘（fire-and-forget）**” 的单向方式。 

其中消息包含两部分内容：**有效载荷（payload）和标签（label）**。 

有效载荷是需要传输的数据，可以是任意内容。
标签描述了有效载荷，RabbitMQ会根据标签的描述，把消息发送给感兴趣的接收方。

# Dubbo面试

## 1.Dubbo支持哪些协议，每种协议的应用场景，优缺点？

- **dubbo：** 单一长连接和NIO异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议TCP，异步，Hessian序列化；
- **rmi：** 采用JDK标准的rmi协议实现，传输参数和返回参数对象需要实现Serializable接口，使用java标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议TCP。 多个短连接，TCP协议传输，同步传输，适用常规的远程服务调用和rmi互操作。在依赖低版本的Common-Collections包，java序列化存在安全漏洞；
- **webservice：** 基于WebService的远程调用协议，集成CXF实现，提供和原生WebService的互操作。多个短连接，基于HTTP传输，同步传输，适用系统集成和跨语言调用；
- **http：** 基于Http表单提交的远程调用协议，使用Spring的HttpInvoke实现。多个短连接，传输协议HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器JS调用；
- **hessian：** 集成Hessian服务，基于HTTP通讯，采用Servlet暴露服务，Dubbo内嵌Jetty作为服务器时默认实现，提供与Hession服务互操作。多个短连接，同步HTTP传输，Hessian序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件；
- **memcache：** 基于memcached实现的RPC协议
- **redis：** 基于redis实现的RPC协议

## 2.Dubbo超时时间怎样设置？

　Dubbo超时时间设置有两种方式：

- 服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。
- 服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。

## 3.Dubbo有些哪些注册中心？

- **Multicast注册中心：** Multicast注册中心不需要任何中心节点，只要广播地址，就能进行服务注册和发现。基于网络中组播传输实现；
- **Zookeeper注册中心：** 基于分布式协调系统Zookeeper实现，采用Zookeeper的watch机制实现数据变更；
- **redis注册中心：** 基于redis实现，采用key/Map存储，住key存储服务名和类型，Map中key存储服务URL，value服务过期时间。基于redis的发布/订阅模式通知数据变更；
- **Simple注册中心**

## 4.Dubbo集群的负载均衡有哪些策略　　

　Dubbo提供了常见的集群策略实现，并预扩展点予以自行实现。

- **Random LoadBalance:** 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀；
- **RoundRobin LoadBalance:** 轮循选取提供者策略，平均分布，但是存在请求累积的问题；
- **LeastActive LoadBalance:** 最少活跃调用策略，解决慢提供者接收更少的请求；
- **ConstantHash LoadBalance:** 一致性Hash策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动；

## 5.核心的配置有哪些

dubbo:service/
dubbo:reference/
dubbo:protocol/
dubbo:registry/
dubbo:application/
dubbo:provider/
dubbo:consumer/
dubbo:method/

## Dubbo集群容错怎么做？

Failover Cluster

　　　　失败自动切换，当出现失败，重试其它服务器 。通常用于读操作，但重试会带来更长延迟。可通过 `retries="2"` 来设置重试次数(不含第一次)。

　　　　`<dubbo:service retries="2" />`

　　　　`<dubbo:reference retries="2" />`

　　　　`<dubbo:reference> <dubbo:method name="findFoo" retries="2" /> </dubbo:reference>`

 　　Failfast Cluster

　　　　快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。

　　Failsafe Cluster

　　　　失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。

　　Failback Cluster

　　　　失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。

　　Forking Cluster

　　　　并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 `forks="2"` 来设置最大并行数

　　Broadcast Cluster

　　　　广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息。

读操作建议使用Failover失败自动切换，默认重试两次其他服务器。写操作建议使用Failfast快速失败，发一次调用失败就立即报错。

## dubbo和dubbox之间的区别？

dubbox是当当网基于dubbo上做了一些扩展，如加了服务可restful调用，更新了开源组件等。

## 你还了解别的分布式框架吗？

别的还有spring的spring cloud，facebook的thrift，twitter的finagle等。 

## 服务提供者能实现失效踢出是什么原理？

服务失效踢出基于zookeeper的临时节点原理。

## 服务上线怎么不影响旧版本？

采用多版本开发，不影响旧版本。

## 如何解决服务调用链过长的问题？

可以结合zipkin实现分布式服务追踪。