## 线程安全
当多个线程访问某一个类、对象或方法时，这个类、对象或方法都能表现出与单线程执行时一致的行为，那么这个类、对象或方法就是线程安全的。

- 线程安全问题都是由全局变量及静态变量引起的
- 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的
- 若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全

### 同步和异步
**同步：** 必须等待方法执行完毕，才能向下执行，共享资源访问的时候，为了保证线程安全，必须同步。 

**异步：** 不用等待其他方法执行完毕，即可立即执行，例如Aja×异步。

#### 对象锁的同步和异步
对象锁只针对 synchronized 修饰的方法生效、对象中的所有 synchronized 方法都会同步执行、而非 synchronized 方法异步执行

> **避免误区：** 类中有两个 synchronized 方法，两个线程分别调用两个方法，相互之间也需要竞争锁，因为两个方法从属于一个对象，而我们是在对象上加锁

### 脏读
由于同步和异步方法的执行个性，如果不从全局上进行并发设计很可能会引起数据的不一致，也就是所谓的脏读。
- 多个线程访问同一个资源，在一个线程修改数据的过程中，有另外的线程来读取数据，就会引起脏读的产生。
- 为了避免脏读我们一定要保证数据修改操作的原子性、并且对读取操作也要进行同步控制

### 锁

#### 重入锁
- 同一个线程得到了一个对象的锁之后，再次请求此对象时可以再次获得该对象的锁。
- 同一个对象内的多个 synchronized 方法可以锁重入
- 父子类可以锁重入

#### 死锁
两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。
此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

#### 锁失效
- 不要在线程中修改对象锁的引用，引用被改变会导致锁失效。
- 在线程中修改了锁对象的属性，而不修改引用则不会引起锁失效、不会产生线程安全问题。  
> 线程A修改了对象锁的引用，则线程B实际的到了新的对象锁，而不是锁被释放了，因此引发了线程安全问题。

#### 锁释放
一个线程在获得锁之后执行操作，发生错误抛出异常，则自动释放锁
1. 可以利用抛出异常，主动释放锁
2. 程序异常时防止资源被死锁、无法释放
3. 异常释放锁可能导致数据不一致，则自动释放锁

#### synchronized
synchronized 的作用是加锁，所有的 synchronized 方法都会顺序执行，（这里只占用CPU的顺序）。

**Synchronized 方法执行方式：**  
- 首先尝试获得锁，如果获得锁，则执行 synchronized 的方法体内容。  
- 如果无法获得锁则等待，并且不断的尝试去获得锁，一旦锁被释放，则多个线程会同时去尝试获得所，造成锁竞争问题。  
- 锁竞争问题，在高并发、线程数量高时会引起CPU占用居高不下，或者直接宕机。  

**Synchronized 锁竞争：**  
- synchronized 可以达到更细粒度的控制当前对象锁、类锁、任意对象锁，同类型锁之间互斥，不同类型的锁之间互不干扰  
- synchronized 作用在非静态方法上代表的对象锁，一个对象一个锁，多个对象之间不会发生锁竞争  
- synchronized 作用在静态方法上则升级为类锁，所有对象共享一把锁，存在锁竞争  

### 线程通信

##### 标识位/变量
使用循环监控标识位或变量

##### wait/notify
- wait 等待，释放锁
- notify 通知等待线程，不释放锁
- notifyAll 通知所有等待线程，不释放锁
- wait/notify 必须与 synchronized 一同使用

### volatile
强制线程到共享内存中读取数据，而不从线程工作内存中读取，从而使变量在多个线程间可见。
volatile 属于轻量级的同步，性能比 synchronized 强很多（不加锁），但是只保证线程见的可见性，并不能替代 synchronized 的同步功能，netty 框架中大量使用了 volatile

> static 保证唯一性，不保证一致性，多个实例共享一个静态变量。
> volatile 保证一致性，不保证唯一性，多个实例有多个 volatile 变量。

### CAS(原子操作)
使用 AtomicInteger 等原子类可以保证共享变量的原子性，但是 Atomic 类不能保证成员方法的原子性

> Atomic 类采用了 CAS 非锁机制

### ThreadLocal
使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

### 容器

#### 同步类容器
Vector、HashTable 等古老的并发容器，都是使用 Collections.synchronized 等工厂方法创建的。
这种方法会在整个对象上加锁，并发状态下只能有一个线程访问容器对象，性能很低。

**使用以下方法使容器支持多线程**
- Collections.synchronizedCollection(Collection<T> c);
- Collections.synchronizedList(List<T> list);
- Collections.synchronizedSet(Set<T> s);
- Collections.synchronizedSortedSet(SortedSet<T> s);
- Collections.synchronizedNavigableSet(NavigableSet<T> s);
- Collections.synchronizedMap(Map<K,V> m);
- Collections.synchronizedSortedMap(TreeMap<K,V> m);
- Collections.synchronizedNavigableMap(NavigableMap<K,V> m);

#### 并发类容器

> JDK5.0 之后提供了多种并发类容易可以替代同步类容器，提升性能、吞吐量

##### Map
- ConcurrentHashMap 替代 HashMap、HashTable
- ConcurrentSkipListMap 替代 TreeMap (Collections.synchronizedSortedMap(TreeMap<K,V> m))
- ConcurrentHashMap 将 hash 分为 16 个 segment，每个 segment 单独进行锁控制，从而减小了锁的粒度，提升性能。
- ConcurrentSkipListMap 线程安全的有序的哈希表，适用于高并发的场景，使用跳表实现。

##### COW(List/Set)
Copy On Write 容器，简称 COW；写时复制容器，向容器中添加元素时，先将容器 copy 出一个新容器，然后将元素添加到新容器中，再将原容器的引用指向新容器。
并发读的时候不需要锁定容器，因为原容器没有变化，使用的是一种读写分离的思想。
由于每次更新都会复制新容器，所以如果数据量较大，并且更新操作频繁则对内存消耗很高，建议在高并发读的场景下使用 

- CopyOnWriteArrayList
- CopyOnWriteArraySet 基于 CopyOnWriteArrayList 实现，其唯一的不同是在add时调用的是 CopyOnWriteArrayList 的 addIfAbsent 方法，adIfAbsent方法同样采用锁保护，并创建一个新的大小 +1 的 Object 数组。
遍历当前 Object 数组，如 Object 数组中己有了当前元素，则直接返回，如果没有则放入Object数组的尾部，并返回。从以上分析可见，copy0nWriteArraySet 在 add 时每次都要进行数组的遍历，因此其性能会低于 CopyOnWriteArrayList.


### 队列
> ConcurrentLinkedQueue 性能优于 BlockingQueue

#### 并发无阻塞式队列
ConcurrentLinkedQueue 并发无阻塞队列，实现 Queue 接口
- 无锁
- 无阻塞
- 高性能
- 线程安全
- 无界(无大小限制)
- 不允许 null 值


#### 并发阻塞式队列

> BlockingQueue(接口) 发阻塞队列，实现 Queue 接口

##### ArrayBlockingQueue:

> 内部实现维护了一个定长数组用于缓存数据，内部没有采用读写分离，写入和读取数据不能同时进行，创建时指定容量。

- 基于数组实现
- 阻塞
- 有界队列
- 不允许 null 值

**方法说明：**
- peek：读取第一个元素；队列为空时，返回 null、不阻塞、不抛异常
- poll：读取第一个元素并移除；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- take：读取第一个元素；队列为空时，永久阻塞、不抛异常
- add：添加，队列满抛出异常
- offer：添加，队列满不阻塞、不抛出异常；可设置阻塞等待时间，超时后不阻塞、不抛异常
- put：添加，队列永远阻塞
- drainTo：取出 maxElements 个元素放入集合 c，并移除；队列为空时，返回 null、不阻塞、不抛异常；  
           int drainTo(Collection<? super E> c, int maxElements = Integer.MAX_VALUE)

##### LinkedBlockingQueue:
> 内部使用链表实现，内部没有采用读写分离，写入和读取数据不能同时进行。与 ArrayBlockingQueue 不同的是，inkedBlockingQueue 创建时可以选择指定或者不指定长度。效率低于 LinkedBlockingQueue。

- 基于链表实现
- 阻塞
- 有界队列 | 无界队列
- 不允许 null 值

**方法说明：**
指定大小时，方法与 ArrayBlockingQueue 操作方法完全一致；不指定大小时，添加不存在队列满的问题。

##### PriorityBlockingQueue:
> 一个带有优先级的无界阻塞队列，默认初始化长度 11，也可以手动指定，但是队列会自动扩容
>
> 资源被耗尽时导致 OutOfMemoryError 
>
> 不允许使用 null
>
> 不允许插入不可比较的对象（导致抛出 ClassCastException），加入的对象需实现 Comparable 接口
>
> 调用 take 方法后才会对元素排序

- 基于数组实现
- 阻塞
- 无界
- 不允许 null 值
- 调用 take 方法后才会对元素排序

**方法说明：**
- peek：读取第一个元素；队列为空时，返回 null、不阻塞、不抛异常
- poll：读取第一个元素并移除；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- take：读取第一个元素；队列为空时，永久阻塞、不抛异常
- add：内部调用了 offer 方法
- put：内部调用了 offer 方法
- offer：添加 ，可指定超时时间，但参数会被忽略
- drainTo：取出 maxElements 个元素放入集合 c，并移除；队列为空时，返回 null、不阻塞、不抛异常；  
           int drainTo(Collection<? super E> c, int maxElements = Integer.MAX_VALUE)

##### SynchronousQueue:
> 没有任何容量，必须现有线程先从队列中 take，才能向 queue 中 add 数据，否则会抛出队列己满的异常。
>
> 不能使用peek方法取数据，此方法底层没有实现，会直接返回 null。

**方法说明：**
- take：读取数据；队列为空时，永久阻塞
- poll：读取数据；队列为空时，返回 null、不阻塞、不抛异常；可指读取定超时时间，超时后返回 null、不阻塞、不抛异常
- add：添加，队列没有线程 take/poll 时抛出异常；
- put：添加，队列没有线程 take/poll 时阻塞；


##### DelayQueue：
> Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。
>
> 该队列的头部是延迟期满后保存时间最长的 Delayed 元素。
>
> 如果延迟都还没有期满，则队列没有头部，并且 p 将返回 null。
>
> 当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于0的值时，将发生到期。
>
> 即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。
>
> 例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用null元素。内部元素需实现 Delayed 接口
>
> 场景：缓存到期删除、任务超时处理、空闲链接关闭等

- 基于 PriorityQueue 实现
- 阻塞
- 无界
- 不允许 null 值

## Concurrent 同步类工具
- CountDownLatch
- CyclicBarrier
- Semaphore
- Exchanger
- ReentrantLock
- ReentrantReadWriteLock

### CountDownLatch
> 允许一个或多个线程等待一系列指定操作的完成。CountDownLatch以一个给定的数量初始化。
>
> countDown() 每被调用一次，这一数量就减一。
>
> 通过调用 await() 方法之一，线程可以阻塞等待这一数量到达零。

**常用方法说明：**

- CountDownLatch(int count)
  - 初始化对象并设置计数大小

- CountDownLatch.await() 
    - 导致当前线程等到锁存器倒计数到零，除非线程是 interrupted 状态。
    - 如果当前计数为零，则此方法立即返回。
    - 如果当前线程在进入此方法时设置其中断状态或者在在等待时被中断，则抛出 InterruptedException 并清除当前线程的中断状态
    - 如果当前计数大于零，则当前线程因线程调度而被禁用，并且在发生以下两种情况之一前处于休眠状态：

        - 由于调用 countDown 方法计数达到零; 
        - 其他线程中断当前线程
- countDownLatch.countDown()   
    - 减少锁存器的计数，如果计数达到零，则释放所有等待的线程。  
    - 如果当前计数大于零，则递减。 
    - 如果新计数为零，则重新启用所有等待线程以进行线程调度。
    - 如果当前计数等于零，则没有任何反应。
- countDownLatch.await(long timeout, TimeUnit unit)
    - 可设置等待超时时间，其他同 countDownLatch.countDown() 方法

- getCount()
  - 返回当前计数，此方法通常用于调试和测试目的

### CyclicBarrier
> 允许一组线程互相等待，直到到达某个公共屏障点(common barrier point)。
>
> 在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时很有用。
>
> 因为该 barrier 在释放等待线程后可以重用，所以称它为循环的 barrier.
>
> 需要所有的子任务都完成时，才执行主任务，这个时候就可以选择使用 CyclicBarrier。

**常用方法说明：**

- CyclicBarrier(int parties, Runnable barrierAction)
  - 创建 CyclicBarrier 并设置等待线程数量，当屏障触发时指定预定义的操作 barrierAction
- CyclicBarrier(int parties)
  - 创建 CyclicBarrier 并设置等待线程数量
- getParties()
  - 返回跳过此障碍所需的参与方数量

- CyclicBarrier.await() 
  - 如果当前线程不是最后一个到达那么它就因线程调度而被禁用，并且在发生以下情况之一前处于休眠状态：
    - 当前线程被其他线程中断
    - 其他线程处于中断或等待状态
    - 其他线程等待屏障超时
    - 其他线程调用 reset 方法重置屏障
  - 如果当前线程在进入此方法时设置其中断状态或在等待时被打断，则抛出 InterruptedException 并且当前线程
      中断状态被清除    
  - 如果任何线程等待时， reset 方法被调用或者屏障状态被破坏，则抛出 BrokenBarrierException
  - 如果任何线程在等待时被中断， 所有其他等待的线程将抛出  BrokenBarrierException，屏障被破坏
- CyclicBarrier.await(long timeout, TimeUnit unit)
  - 可设置等待超时时间，其他同 CyclicBarrier.countDown() 方法
- CyclicBarrier.isBroken()   
  - 查询此屏障是否处于损坏状态。  

- CyclicBarrier.reset()
  - 将屏障重置为其初始状态。
  - 如果任何一方正在等待屏障，他们将返回 BrokenBarrierException。
  - 由于其他原因发生破损后的重置可能很复杂；线程需要以其他方式重新同步，并选择一个来执行重置。如果可能，最好为线程创建新的屏障。
- CyclicBarrier.getNumberWaiting()
  - 返回当前在屏障处等待的方数。此方法主要用于调试和断言。

### Semaphore

> semaphore —个计数信号量。信号量维护了一八许可集合；通过 acquire() 和 release() 来获取和释放访问许可证。只有通过acuire获取了许可证的线程才能执行，否则阻塞。通过 release 释放许可证其私线程才能进行获取。
>
> Semaphore有两种模式，公平模式和非公平模式。公平模式就是调用acquire的顺序就是获取许可证的顺序，遵循FIFO；而非公平模式是抢占式的，也就是有可能一个新的获取线程恰好在一个许可证释放时得到了这个许可证，而前面还有等待的线程。

### Exchanger

### ReentrantLock

### ReentrantReadWriteLock

## 线程池

newCachedThreadPool

> 具有缓存性质的线程池，线程最大空闲时间60s，线程可重复利用（缓存特性)，没有最大线程数限制。任务耗时端，数量大。

newFixedThreadPool 

> 具有固定数量的线程池，核心线程数等于最大线程数，线程最大空闲时间为0，执行完毕即销毁，超出最大线程数进行等待。高并发下控制性能。

newScheduledThreadPool 

> 具有时间调度特性的线程池，必须初始化核心线程数，底层使用 DelayedWorkQueue 实现延迟特性。

newSingleThreadExecutor 

> 核心线程数与最大线程数均为1，用于不需要并发顺序执行。

```java
public class ThreadPoolExecutor extends AbstractExecutorService {
    .....
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
            BlockingQueue<Runnable> workQueue,RejectedExecutionHandler handler);
 
    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,
        BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);
    ...
}

public abstract class AbstractExecutorService implements ExecutorService {
 
    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) { };
    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) { };
    public Future<?> submit(Runnable task) {};
    public <T> Future<T> submit(Runnable task, T result) { };
    public <T> Future<T> submit(Callable<T> task) { };
    
    private <T> T doInvokeAny(Collection<? extends Callable<T>> tasks, boolean timed, long nanos)
        throws InterruptedException, ExecutionException, TimeoutException {
    };
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks)
        throws InterruptedException, ExecutionException {
    };
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks,
                           long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException {
    };
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException {
    };
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
        throws InterruptedException {
    };
}
```



### 参数说明

#### corePoolSize

核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了 prestartAllCoreThreads() 或者prestartCoreThread() 方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建 corePoolSize 个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到 corePoolSize 后，就会把到达的任务放到缓存队列当中；

#### maximumPoolSize

线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；

#### keepAliveTime

表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；

#### unit

参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性：

- TimeUnit.DAYS;               //天
- TimeUnit.HOURS;             //小时
- TimeUnit.MINUTES;           //分钟
- TimeUnit.SECONDS;            //秒
- TimeUnit.MILLISECONDS;      //毫秒
- TimeUnit.MICROSECONDS;      //微妙
- TimeUnit.NANOSECONDS;       //纳秒

#### workQueue

一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：

- ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务； 
- LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQuene； 
- SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene； 
- DelayedWorkQueue：支持定时
- PriorityBlockingQuene：有优先级的无界阻塞队列；

#### threadFactory

创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为`DefaultThreadFactory`，即`AbortPolicy`

#### handler

线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，有以下四种取值：

- ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。 
- ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 
- ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
- ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 

> 也可以根据应用场景实现 RejectedExecutionHandler 接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。


## 线程设计模式

### Future

> 简单来说，客户端请求之后，先返回一个应答结果，然后异步的去准备数据，客户端可以先去处理其他事情，当需要最终结果的时候再来获取，如果此时数据己经准备好，则将真实数据返回；如果此时数据还没有准备好，则阻塞等待。

```java
ExecutorService executorService = Executors.newFixedThreadPool(2);
Future<?> future = executorService.submit(new Caller("12345"));
Future<?> future1 = executorService.submit(new Caller("54321"));
Thread.sleep(2000);
System.out.println("Result: " + future.get());
System.out.println("Result: " + future1.get());
executorService.shutdown();

class Caller implements Callable<String> {
    private String string;
    public Caller(String string) {
        this.string = string;
    }    
    @Override
    public String call() throws Exception {
        Thread.sleep(5000);
        return string + "22222222";
    }   
}
```



### Master-Worker

> Master一worker模式是一种将串行任务并行化的方案，被分解的子任务在系统中可以被并行处理，同时，如果有需要，Master进程不需要等待所有子任务都完成计算，就可以根据己有的部分结果集计算最终结果集。
>
> 客户端将所有任务提交给Master，Master分配worker去并发处理任务，并将每一个任务的处理结果返回给Master，所有的任务处理完毕后，由Master进行结果汇总再返回给Client



### Producer-Consumer（生产者消费者）








# Disruptor 高并发框架


# RateLimiter 高并发访问限流

















